{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Health Prediction from Infrared Spectroscopy\n",
    "\n",
    "This notebook demonstrates how to predict soil properties (Ca, P, pH, SOC, Sand) from mid-infrared spectral absorption measurements using machine learning.\n",
    "\n",
    "## Problem Overview\n",
    "\n",
    "- **Input**: 3,578 mid-infrared spectral features per sample\n",
    "- **Output**: 5 continuous soil properties (multi-target regression)\n",
    "- **Challenge**: High-dimensional data (more features than samples)\n",
    "- **Solution**: Regularized models, spectral preprocessing, proper validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import our custom modules\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from preprocessing import preprocess_pipeline, snv_correction, savitzky_golay_filter\n",
    "from utils import (\n",
    "    load_afsis_data,\n",
    "    standardize_targets,\n",
    "    inverse_transform_targets,\n",
    "    evaluate_predictions,\n",
    "    print_evaluation_results\n",
    ")\n",
    "from models import (\n",
    "    RidgeRegressionCV,\n",
    "    PLSBaseline,\n",
    "    RandomForestPCA,\n",
    "    DeepLearningModel\n",
    ")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data\n",
    "\n",
    "Download the data from Kaggle:\n",
    "https://www.kaggle.com/c/afsis-soil-properties/data\n",
    "\n",
    "Place the CSV files in a `data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (update path as needed)\n",
    "# X, y = load_afsis_data('../data/training.csv')\n",
    "\n",
    "# For demonstration, create synthetic data\n",
    "print(\"Creating synthetic data for demonstration...\")\n",
    "n_samples = 1000\n",
    "n_features = 3578\n",
    "n_targets = 5\n",
    "\n",
    "X = np.random.randn(n_samples, n_features) * 0.1 + np.random.rand(n_samples, 1)\n",
    "y = np.random.randn(n_samples, n_targets) * 10 + np.array([5000, 30, 6.5, 2.0, 50])\n",
    "\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "target_names = ['Ca', 'P', 'pH', 'SOC', 'Sand']\n",
    "stats_df = pd.DataFrame(y, columns=target_names).describe()\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Spectral Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample spectra\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "for i in range(5):\n",
    "    ax.plot(X[i], alpha=0.7, label=f'Sample {i+1}')\n",
    "\n",
    "ax.set_xlabel('Wavenumber Index')\n",
    "ax.set_ylabel('Absorption')\n",
    "ax.set_title('Sample Mid-Infrared Spectra')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Splitting\n",
    "\n",
    "Split data into training and validation sets. In practice, you should split by geographic sites to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Validation set: X={X_val.shape}, y={y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spectral Preprocessing\n",
    "\n",
    "Apply preprocessing to remove noise and standardize spectra:\n",
    "- **SNV (Standard Normal Variate)**: Removes multiplicative scatter effects\n",
    "- **Savitzky-Golay**: Smooths spectra while preserving features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess spectral data\n",
    "X_train_prep = preprocess_pipeline(X_train, methods=['snv', 'savgol'])\n",
    "X_val_prep = preprocess_pipeline(X_val, methods=['snv', 'savgol'])\n",
    "\n",
    "# Visualize preprocessing effect\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(X_train[0], alpha=0.7, label='Raw')\n",
    "axes[0].set_title('Raw Spectrum')\n",
    "axes[0].set_xlabel('Wavenumber Index')\n",
    "axes[0].set_ylabel('Absorption')\n",
    "\n",
    "axes[1].plot(X_train_prep[0], alpha=0.7, label='Preprocessed', color='orange')\n",
    "axes[1].set_title('Preprocessed Spectrum (SNV + Savitzky-Golay)')\n",
    "axes[1].set_xlabel('Wavenumber Index')\n",
    "axes[1].set_ylabel('Absorption')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Target Standardization\n",
    "\n",
    "Standardize each target independently since they have vastly different scales (pH: 4-9 vs Ca: 0-40,000 ppm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize targets\n",
    "y_train_scaled, y_val_scaled, scalers = standardize_targets(y_train, y_val)\n",
    "\n",
    "print(\"Target standardization complete.\")\n",
    "print(f\"Scaled training targets: mean={y_train_scaled.mean(axis=0)}, std={y_train_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Baseline Models\n",
    "\n",
    "### 7.1 Ridge Regression with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Ridge Regression\n",
    "print(\"Training Ridge Regression with CV...\")\n",
    "ridge_model = RidgeRegressionCV(cv=5)\n",
    "ridge_model.fit(X_train_prep, y_train_scaled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ridge_scaled = ridge_model.predict(X_val_prep)\n",
    "y_pred_ridge = inverse_transform_targets(y_pred_ridge_scaled, scalers)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nRidge Regression Results:\")\n",
    "ridge_results = evaluate_predictions(y_val, y_pred_ridge, target_names)\n",
    "print_evaluation_results(ridge_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Partial Least Squares (PLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PLS\n",
    "print(\"Training PLS...\")\n",
    "pls_model = PLSBaseline(n_components=50)\n",
    "pls_model.fit(X_train_prep, y_train_scaled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_pls_scaled = pls_model.predict(X_val_prep)\n",
    "y_pred_pls = inverse_transform_targets(y_pred_pls_scaled, scalers)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nPLS Results:\")\n",
    "pls_results = evaluate_predictions(y_val, y_pred_pls, target_names)\n",
    "print_evaluation_results(pls_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest with PCA...\")\n",
    "rf_model = RandomForestPCA(n_components=50, n_estimators=100)\n",
    "rf_model.fit(X_train_prep, y_train_scaled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf_scaled = rf_model.predict(X_val_prep)\n",
    "y_pred_rf = inverse_transform_targets(y_pred_rf_scaled, scalers)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "rf_results = evaluate_predictions(y_val, y_pred_rf, target_names)\n",
    "print_evaluation_results(rf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Models\n",
    "\n",
    "### 8.1 1D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 1D CNN\n",
    "print(\"Training 1D CNN...\")\n",
    "cnn_model = DeepLearningModel(\n",
    "    model_type='conv1d',\n",
    "    input_size=X_train_prep.shape[1],\n",
    "    n_targets=y_train_scaled.shape[1],\n",
    "    epochs=50,  # Use fewer epochs for demo\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "cnn_model.fit(X_train_prep, y_train_scaled, X_val_prep, y_val_scaled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_cnn_scaled = cnn_model.predict(X_val_prep)\n",
    "y_pred_cnn = inverse_transform_targets(y_pred_cnn_scaled, scalers)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\n1D CNN Results:\")\n",
    "cnn_results = evaluate_predictions(y_val, y_pred_cnn, target_names)\n",
    "print_evaluation_results(cnn_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Multi-Task Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Multi-Task Network\n",
    "print(\"Training Multi-Task Network...\")\n",
    "mt_model = DeepLearningModel(\n",
    "    model_type='multitask',\n",
    "    input_size=X_train_prep.shape[1],\n",
    "    n_targets=y_train_scaled.shape[1],\n",
    "    epochs=50,  # Use fewer epochs for demo\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "mt_model.fit(X_train_prep, y_train_scaled, X_val_prep, y_val_scaled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_mt_scaled = mt_model.predict(X_val_prep)\n",
    "y_pred_mt = inverse_transform_targets(y_pred_mt_scaled, scalers)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nMulti-Task Network Results:\")\n",
    "mt_results = evaluate_predictions(y_val, y_pred_mt, target_names)\n",
    "print_evaluation_results(mt_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "all_results = {\n",
    "    'Ridge': ridge_results,\n",
    "    'PLS': pls_results,\n",
    "    'Random Forest': rf_results,\n",
    "    '1D CNN': cnn_results,\n",
    "    'Multi-Task': mt_results\n",
    "}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "for model_name, results in all_results.items():\n",
    "    for target in target_names:\n",
    "        comparison_data.append({\n",
    "            'Model': model_name,\n",
    "            'Target': target,\n",
    "            'RMSE': results[target]['RMSE'],\n",
    "            'RPD': results[target]['RPD']\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "pivot_rmse = comparison_df.pivot(index='Model', columns='Target', values='RMSE')\n",
    "pivot_rmse.plot(kind='bar', ax=axes[0], width=0.8)\n",
    "axes[0].set_title('RMSE Comparison by Target')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].legend(title='Target', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# RPD comparison\n",
    "pivot_rpd = comparison_df.pivot(index='Model', columns='Target', values='RPD')\n",
    "pivot_rpd.plot(kind='bar', ax=axes[1], width=0.8)\n",
    "axes[1].set_title('RPD Comparison by Target')\n",
    "axes[1].set_ylabel('RPD (higher is better)')\n",
    "axes[1].axhline(y=2.0, color='r', linestyle='--', label='Good (RPD=2.0)')\n",
    "axes[1].axhline(y=3.0, color='g', linestyle='--', label='Excellent (RPD=3.0)')\n",
    "axes[1].legend(title='Target', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nModel Rankings by Mean RPD:\")\n",
    "mean_rpd = {}\n",
    "for model_name, results in all_results.items():\n",
    "    mean_rpd[model_name] = results['Mean']['RPD']\n",
    "\n",
    "ranking_df = pd.DataFrame.from_dict(mean_rpd, orient='index', columns=['Mean RPD'])\n",
    "ranking_df = ranking_df.sort_values('Mean RPD', ascending=False)\n",
    "print(ranking_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Prediction Scatter Plots\n",
    "\n",
    "Visualize predictions vs. actual values for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Ridge predictions for visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, target in enumerate(target_names):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(y_val[:, i], y_pred_ridge[:, i], alpha=0.5)\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    min_val = min(y_val[:, i].min(), y_pred_ridge[:, i].min())\n",
    "    max_val = max(y_val[:, i].max(), y_pred_ridge[:, i].max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
    "    \n",
    "    ax.set_xlabel(f'Actual {target}')\n",
    "    ax.set_ylabel(f'Predicted {target}')\n",
    "    ax.set_title(f'{target} (RÂ² = {ridge_results[target][\"R2\"]:.3f})')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary and Next Steps\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Preprocessing is critical**: SNV and Savitzky-Golay smoothing improve model performance\n",
    "2. **Regularization is essential**: Ridge regression works well for high-dimensional data\n",
    "3. **PLS is effective**: Standard chemometrics baseline performs competitively\n",
    "4. **Deep learning potential**: CNNs can capture local spectral patterns\n",
    "5. **Multi-task learning**: Joint prediction can leverage correlations between soil properties\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Download real data**: Use the Africa Soil Property Prediction dataset from Kaggle\n",
    "2. **Geographic splitting**: Split by site IDs to avoid data leakage\n",
    "3. **Hyperparameter tuning**: Optimize model parameters with cross-validation\n",
    "4. **Ensemble methods**: Combine multiple models for better predictions\n",
    "5. **Feature engineering**: Try different preprocessing methods and combinations\n",
    "6. **Scale up**: Use the iSDA AfSIS Full Release with 50,000+ samples\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- Kaggle Competition: https://www.kaggle.com/c/afsis-soil-properties\n",
    "- iSDA AfSIS Data: https://www.isda-africa.com/\n",
    "- Documentation: See README.md for more details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
