{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Africa Soil Property Prediction - Example Notebook\n",
    "\n",
    "This notebook demonstrates how to use the soil property prediction package to train models and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from src.data_preprocessing import SoilDataPreprocessor, handle_missing_values\n",
    "from src.models import MultiTargetSoilPredictor, EnsemblePredictor\n",
    "from src.feature_engineering import SpectralFeatureEngineer\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = SoilDataPreprocessor()\n",
    "\n",
    "# Load training data\n",
    "train_df = preprocessor.load_data('../data/train.csv')\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target distributions\n",
    "target_cols = ['Ca', 'P', 'pH', 'SOC', 'Sand']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(target_cols):\n",
    "    if col in train_df.columns:\n",
    "        axes[i].hist(train_df[col], bins=30, edgecolor='black')\n",
    "        axes[i].set_title(f'{col} Distribution')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "train_df = handle_missing_values(train_df, strategy='mean')\n",
    "\n",
    "# Prepare features and targets\n",
    "X = preprocessor.prepare_features(train_df, fit=True)\n",
    "y = preprocessor.prepare_targets(train_df)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target matrix shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_val, y_train, y_val = preprocessor.split_data(X, y, test_size=0.2)\n",
    "\n",
    "print(f\"Training set: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Validation set: X={X_val.shape}, y={y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "rf_model = MultiTargetSoilPredictor(\n",
    "    model_type='random_forest',\n",
    "    n_estimators=100,\n",
    "    max_depth=None\n",
    ")\n",
    "\n",
    "rf_model.train(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "rf_metrics = rf_model.evaluate(X_val, y_val)\n",
    "rf_model.print_evaluation(rf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "xgb_model = MultiTargetSoilPredictor(\n",
    "    model_type='xgboost',\n",
    "    n_estimators=100,\n",
    "    max_depth=6\n",
    ")\n",
    "\n",
    "xgb_model.train(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "xgb_metrics = xgb_model.evaluate(X_val, y_val)\n",
    "xgb_model.print_evaluation(xgb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare R2 scores\n",
    "models = ['Random Forest', 'XGBoost']\n",
    "r2_scores = [\n",
    "    rf_metrics['overall']['R2'],\n",
    "    xgb_metrics['overall']['R2']\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, r2_scores)\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('Model Comparison - Overall R² Score')\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# Plot actual vs predicted for each target\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, target in enumerate(target_cols):\n",
    "    if i < y_val.shape[1]:\n",
    "        axes[i].scatter(y_val[:, i], y_pred_rf[:, i], alpha=0.5)\n",
    "        axes[i].plot([y_val[:, i].min(), y_val[:, i].max()], \n",
    "                     [y_val[:, i].min(), y_val[:, i].max()], \n",
    "                     'r--', lw=2)\n",
    "        axes[i].set_xlabel(f'Actual {target}')\n",
    "        axes[i].set_ylabel(f'Predicted {target}')\n",
    "        axes[i].set_title(f'{target} - Actual vs Predicted')\n",
    "        \n",
    "        # Add R² score\n",
    "        r2 = rf_metrics['per_target'][target]['R2']\n",
    "        axes[i].text(0.05, 0.95, f'R² = {r2:.3f}', \n",
    "                    transform=axes[i].transAxes, \n",
    "                    verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "feature_engineer = SpectralFeatureEngineer()\n",
    "X_pca = feature_engineer.apply_pca(X, n_components=50, fit=True)\n",
    "\n",
    "print(f\"Original shape: {X.shape}\")\n",
    "print(f\"PCA shape: {X_pca.shape}\")\n",
    "\n",
    "# Plot explained variance\n",
    "variance_ratio = feature_engineer.get_explained_variance_ratio()\n",
    "cumulative_variance = feature_engineer.get_cumulative_variance()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax1.bar(range(len(variance_ratio)), variance_ratio)\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Explained Variance Ratio')\n",
    "ax1.set_title('Explained Variance by Component')\n",
    "\n",
    "ax2.plot(range(len(cumulative_variance)), cumulative_variance)\n",
    "ax2.set_xlabel('Number of Components')\n",
    "ax2.set_ylabel('Cumulative Explained Variance')\n",
    "ax2.set_title('Cumulative Explained Variance')\n",
    "ax2.axhline(y=0.9, color='r', linestyle='--', label='90% variance')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCumulative variance explained: {cumulative_variance[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "import joblib\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "rf_model.save_model('../models/random_forest_model.pkl')\n",
    "joblib.dump(preprocessor, '../models/preprocessor.pkl')\n",
    "\n",
    "print(\"Model and preprocessor saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. Loaded and explored the soil spectral data\n",
    "2. Preprocessed features and targets\n",
    "3. Trained multiple models (Random Forest, XGBoost)\n",
    "4. Evaluated model performance\n",
    "5. Visualized predictions vs actual values\n",
    "6. Applied PCA for dimensionality reduction\n",
    "7. Saved the trained model\n",
    "\n",
    "The models successfully predict five soil properties from infrared spectral data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
